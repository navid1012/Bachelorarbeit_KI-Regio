{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importieren, benötigter Packages und einlesen der Trainings- und Testdaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "datensatz = pd.read_csv(\"./foot-traffic-wue/train.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trainingsdaten nach Fehlern und unrelevanten Daten bereinigen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datensatz_f = datensatz[\n",
    "    ~datensatz['incidents'].isin(['laser_failure']) \n",
    "    ]\n",
    "\n",
    "datensatz_f.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Markierung der Feiertage im Datensatz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liste der Feiertage\n",
    "feiertage = [\n",
    "    '2019-04-19', '2019-04-22', '2019-05-01', '2019-05-30', '2019-06-10', '2019-06-20', '2019-08-15',\n",
    "    '2019-10-03', '2019-11-01', '2019-12-25', '2019-12-26', '2020-01-01', '2020-01-06', '2020-04-10',\n",
    "    '2020-04-13', '2020-05-01', '2020-05-21', '2020-06-01', '2020-06-11', '2020-08-15', '2020-10-03',\n",
    "    '2020-11-01', '2020-12-25', '2020-12-26', '2021-01-01', '2021-01-06', '2021-04-02', '2021-04-05',\n",
    "    '2021-05-01', '2021-05-13', '2021-05-24', '2021-06-03', '2021-08-15', '2021-10-03', '2021-11-01',\n",
    "    '2021-12-25', '2021-12-26', '2022-01-01', '2022-01-06', '2022-04-15', '2022-04-18', '2022-05-01',\n",
    "    '2022-05-26', '2022-06-06', '2022-06-16', '2022-08-15', '2022-10-03', '2022-11-01', '2022-12-25',\n",
    "    '2022-12-26', '2023-01-01', '2023-01-06', '2023-04-07', '2023-04-10', '2023-05-01', '2023-05-18',\n",
    "    '2023-05-29', '2023-06-08', '2023-08-15', '2023-10-03', '2023-11-01', '2023-12-25', '2023-12-26',\n",
    "    '2024-01-01', '2024-01-06', '2024-03-29', '2024-04-01', '2024-05-01', '2024-05-09', '2024-05-20',\n",
    "    '2024-05-30', '2024-08-15'\n",
    "]\n",
    "\n",
    "# Konvertiere die Feiertage zu einem Set für eine schnellere Suche\n",
    "feiertage_set = set(feiertage)\n",
    "\n",
    "# Erstelle die neue Spalte \"is_feiertag\"\n",
    "datensatz_f['is_feiertag'] = datensatz_f['date'].apply(lambda x: 1 if x in feiertage_set else 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aufteilung der Spalte date in year, month und day "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Konvertiere die Spalte 'date' in ein Datetime-Format\n",
    "datensatz_f['date'] = pd.to_datetime(datensatz_f['date'])\n",
    "\n",
    "# Zerlege die Spalte in 'year', 'month' und 'day'\n",
    "datensatz_f['year'] = datensatz_f['date'].dt.year\n",
    "datensatz_f['month'] = datensatz_f['date'].dt.month\n",
    "datensatz_f['day'] = datensatz_f['date'].dt.day\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zusammenführen der Wetterbedingungen, welche in Tag und Nacht unterteilt sind "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Werte zusammenführen\n",
    "datensatz_f['weather_condition'] = datensatz_f['weather_condition'].replace({\n",
    "    'partly-cloudy-day': 'partly-cloudy',\n",
    "    'partly-cloudy-night': 'partly-cloudy',\n",
    "    'clear-day': 'clear',\n",
    "    'clear-night': 'clear'\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aufstellen des Modells mit Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "# Daten laden (Hier muss der korrekte DataFrame 'datensatz_f' bereits existieren)\n",
    "feature_columns = [\"streetname\", \"hour\", \"weekday\", \"weather_condition\", \"incidents\", \"temperature\", \"year\", \"month\", \"day\"]\n",
    "target_columns = [\"n_pedestrians\", \"n_pedestrians_towards\", \"n_pedestrians_away\"]\n",
    "\n",
    "X = datensatz_f[feature_columns]\n",
    "Y = datensatz_f[target_columns]\n",
    "\n",
    "# Kategorische Spalten encodieren\n",
    "categorical_columns = [\"streetname\", \"weekday\", \"weather_condition\", \"incidents\"]\n",
    "encoder = OrdinalEncoder()\n",
    "X_categorical_encoded = encoder.fit_transform(X[categorical_columns])\n",
    "X_categorical_encoded_df = pd.DataFrame(X_categorical_encoded, columns=encoder.get_feature_names_out(categorical_columns))\n",
    "\n",
    "# Numerische Features hinzufügen\n",
    "X_encoded = pd.concat([X_categorical_encoded_df, X[[\"hour\", \"temperature\", \"year\", \"month\", \"day\"]].reset_index(drop=True)], axis=1)\n",
    "\n",
    "# Sicherstellen, dass X_train und Y_train synchron sind\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_encoded, Y, test_size=0.1, random_state=42)\n",
    "\n",
    "# 10-fache Cross validation\n",
    "kf = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "# Hyperparameter-Grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],  \n",
    "    'max_depth': [10, 30, 50],\n",
    "    'max_features': [0.3, 0.5, 1.0],\n",
    "}\n",
    "\n",
    "\n",
    "# Grid Search für Random Forest\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=kf, scoring='neg_mean_squared_error', n_jobs=32, verbose=0)\n",
    "grid_search.fit(X_encoded, Y)\n",
    "\n",
    "# Beste Parameter ausgeben\n",
    "print(\"Beste Parameterwerte:\")\n",
    "for param, value in grid_search.best_params_.items():\n",
    "    print(f\"{param}: {value}\")\n",
    "\n",
    "# Bestes Modell trainieren\n",
    "best_params = grid_search.best_params_\n",
    "best_rf_model = RandomForestRegressor(n_estimators=best_params['n_estimators'], max_depth=best_params['max_depth'], max_features=best_params['max_features'], random_state=42)\n",
    "best_rf_model.fit(X_train, Y_train)\n",
    "\n",
    "# Vorhersagen\n",
    "best_predictions = best_rf_model.predict(X_test)\n",
    "\n",
    "# Fehlerberechnung\n",
    "mse = mean_squared_error(Y_test, best_predictions)\n",
    "rmse = np.sqrt(mse)\n",
    "print(f\"Beste MSE: {mse}\")\n",
    "print(f\"Beste RMSE: {rmse}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
